{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6d4196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "#Los archivos están en la misma carpeta que este .ipynb\n",
    "clientes = pd.read_excel('./maestro_clientes.xlsx')\n",
    "productos = pd.read_csv('./maestro_productos.csv') \n",
    "proveedor_1 = pd.read_csv('./sellout-proveedor1.csv.gz',compression = 'gzip',sep = '|') # el separador de estos archivos\n",
    "proveedor_2 = pd.read_csv('./sellout-proveedor2.csv.gz',compression = 'gzip',sep = '|') # es | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0173ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularmente empiezo viendo los detalles más simples para asegurarme que tengo la tabla correcta.\n",
    "# clientes.info()\n",
    "# clientes.sample(10)\n",
    "# productos.info()\n",
    "# productos.sample(10)\n",
    "# proveedor_1.info()\n",
    "# proveedor_1.sample(10)\n",
    "# proveedor_2.info()\n",
    "# proveedor_2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b99158da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Regularmente cambio las columnas a tipos adecuados en otras tablas.\n",
    "precios_numericos = pd.to_numeric(proveedor_2['Price'].str.replace('$','',regex=True),errors='raise')\n",
    "proveedor_2f = proveedor_2.assign(Price = precios_numericos)\n",
    "proveedor_2f['Date'] = pd.to_datetime(proveedor_2['Date'],format = '%Y/%m/%d')\n",
    "proveedor_1f = proveedor_1.copy()\n",
    "proveedor_1f['Date'] = pd.to_datetime(proveedor_1['Date'],format= '%Y-%m-%d SO Diaria Piezas')\n",
    "# proveedor_1f.info()\n",
    "# proveedor_2f.info() # Para probar que los tipos están correctos y no fallaron en la conversión.\n",
    " \n",
    "# Los siguientes puntos se hacen más fáciles si agrupamos estas dos tablas en una.\n",
    "proveedor_1f = proveedor_1f.rename({'Units':'Pieces'},axis = 'columns')\n",
    "data = pd.concat([proveedor_1f,proveedor_2f],ignore_index=True) # ignorar el indice es bueno para no tener indices repetidos\n",
    "# data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f1d440",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2397549 son entradas con una fracción en \"Pieces\"\n"
     ]
    }
   ],
   "source": [
    "# Cuando revise los documentos note que hay algunos detalles en los datos:\n",
    "# Hay algunas filas con precio 0 y piezas 0, esto probablemente es un error.\n",
    "# Hay algunas filas con piezas mayor que 0 y precio 0, posiblemente un error.\n",
    "\n",
    "ceros = data[data['Price']+data['Pieces'] == 0]\n",
    "cero_costo = data[(data['Price']==0) & (data['Pieces'] > 0)]\n",
    "# ceros.info(),cero_costo.info() # Hay 568,000 en el primer caso y 110 en el segundo.\n",
    "\n",
    "# Creo que quitar estos datos es necesario, pero en cualquier caso se puede cambiar de tabla si es necesario.\n",
    "data_limpia = data[~data.index.isin(list(cero_costo.index)+list(ceros.index))]\n",
    "#data_limpia.info()\n",
    "\n",
    "# Otro posible problema son entradas en la columna piezas  que no son enteros, lo cual es un posible error.\n",
    "# Estos representan casi la mitad de todas las  entradas en la tabla de ventas.\n",
    "\n",
    "print(str(len(data_limpia[data_limpia['Pieces'] != data_limpia['Pieces'].astype(int)]))+ ' son entradas con una fracción en \"Pieces\"')\n",
    "\n",
    "# Opte por no considerarlo un error, pero sino fuera un test preguntaria un poco más por este detalle.\n",
    "# data_entera = data_limpia[data_limpia[(data_limpia['Pieces'] != data_limpia['Pieces'].astype(int)])]\n",
    "# En caso de que esas entradas se consideren un error se puede ocupar esta tabla.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db4330ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parece que la tabla de clientes se conecta a la de ventas por medio de 'Store_Id = NUM TDA'\n",
    "# sin embargo existen entradas que su Store_Id no esta en ninguna entrada de clientes\n",
    "sin_tienda = data[~data['Store_Id'].isin(clientes['NUM TDA'])]\n",
    "\n",
    "# [174, 712, 681,  78,  94, 301, 675, 676, 709, 711]  son todos los Store_id que no están en \n",
    "# NUM TDA de un total de 2324 Store_Id distinto, no es necesario remover estas filas de  los datos pero no tendrán \n",
    "# un proveedor ni una tienda asignada, El total de filas en ese estado es 34100.\n",
    "\n",
    "# Por otro lado  \n",
    "sin_compras = clientes[~ clientes['NUM TDA'].isin(data['Store_Id'])]\n",
    "# son todas las tiendas que no tienen ninguna venta (entrada en sellout) su tamaño es 133 de un total de 2448\n",
    "# sin_compras.groupby(['CADENA','ESTADO']).count()['NUM TDA']\n",
    "# muestra que 5 son del proveedor_1 y las demás del proveedor_2 (interesante pero en otro tema)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63333f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 32 distintos en la tabla\n"
     ]
    }
   ],
   "source": [
    "# Quiero saber cuantos estados distinto hay en la tabla \n",
    "print('Hay ' + str(len(clientes['ESTADO'].unique())) +' distintos en la tabla')\n",
    "\n",
    "# El numero de diferentes estados en la tabla de clientes es 32 \n",
    "# Quiero saber que en que estado esta cada tienda y a que cadena pertenece\n",
    "estados = clientes[['CADENA','ESTADO','NUM TDA']].drop_duplicates()\n",
    "estados_activos = estados[['CADENA','ESTADO']].drop_duplicates().groupby(['CADENA']).count()\n",
    "#   |CADENA      |   ESTADO |\n",
    "#   |:-----------|---------:|\n",
    "#   | proveedor_1|       26 |\n",
    "#   | proveedor_2|       32 |\n",
    "# Nos dice que el proveedor 2 no tiene ninguna tienda en 6 estados y entonces técnicamente no cubren todo el país \n",
    "# Incluso suponiendo que el país no es México pues proveedor 2 tiene 32 estados en esa tabla.\n",
    "# Estados.drop_duplicates().groupby(['CADENA','ESTADO']).count() muestra que la cantidad de tiendas entre el \n",
    "# proveedor 1 y proveedor 2 es grande, siendo proveedor 2 significativamente más grande.\n",
    "\n",
    "# Quiero saber si todos los estados tienen al menos una venta con cada proveedor.\n",
    "# Primero agrego los estados pegandolos con 'Store_ID' y 'NUM TDA'\n",
    "# Hay 4 tiendas que están repetidas\n",
    "clientes = clientes[~clientes['NUM TDA'].duplicated(keep= 'last')]\n",
    "clientes_dic = clientes.set_index('NUM TDA').to_dict(orient = 'index')\n",
    "data_limpia.loc[:,'Estado'] = data_limpia['Store_Id'].apply(lambda x: clientes_dic.get(x,dict()).get('ESTADO',None))\n",
    "data_limpia.loc[:,'Cadena'] = data_limpia['Store_Id'].apply(lambda x: clientes_dic.get(x,dict()).get('CADENA',None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f024265a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alfthrilmad'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora podemos saber en que estado tiene ventas cada proveedor.\n",
    "cadena_estado = data_limpia[['Cadena','Estado']].drop_duplicates()\n",
    "# print(cadena_estado['Cadena'].value_counts())\n",
    "# print(cadena_estado.sort_values(by='Cadena'))\n",
    "\n",
    "# Hay un estado donde el proveedor 1 no tiene ventas en el archivo.\n",
    "sin_ventas1 = clientes[~clientes['ESTADO'].isin(data_limpia[data_limpia['Cadena']== 'proveedor_1']['Estado'])]\n",
    "sin_ventas1[sin_ventas1['CADENA'] == 'proveedor_1']['ESTADO'].unique()\n",
    "# El estado es 'Alfthrilmad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f0e5a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uno de los puntos es comprobar que los datos deben contener ventas para cada producto\n",
    "# SKU es lo que identifica a las ventas con los productos entonces si  cada producto tiene ventas \n",
    "productos['Sku'].isin(data['Sku']).all() # Deberia ser Cierto\n",
    "\n",
    "# Esto es falso, de manera especifica todas las ventas correspenden a 47 Sku distintos la tabla con sus \n",
    "# especificaciones:\n",
    "sku = productos[productos['Sku'].isin(data['Sku'])]\n",
    "# Todas pertenecen a las subcategorias 'Cereal bars' y 'Cereal box'.\n",
    "\n",
    "# print(productos['Sku'].duplicated().sum() == 0) # nos dice que no hay 'Sku' repetidos \n",
    "# se genera un diccionario para poder agregar columnas de manera rapida\n",
    "productos_dic = productos.set_index('Sku').to_dict(orient = 'index')\n",
    "\n",
    "# Agrego la descripción del producto solo por que me gusta más ver los nombres.\n",
    "data_limpia.loc[:,'Descripcion'] = data_limpia['Sku'].apply(lambda x: productos_dic[x]['Sku_Description'])\n",
    "\n",
    "# Agregado simple de cada producto \n",
    "resumen_producto = data_limpia.groupby('Descripcion').agg({'Price':'sum','Pieces':'sum','Store_Id':'nunique',})\n",
    "# print(resumen_producto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e674307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 productos tienen ventas todos los dias\n",
      "Descripcion\n",
      "Toast Mango Peach                             520\n",
      "Grape-Nuts Mango Peach                        520\n",
      "Crunch Mango Peach                            520\n",
      "Frosted Chocolate Choc Chip                   520\n",
      "Crunch Chocolate Choc Chip                    520\n",
      "Chocos Mango Peach                            520\n",
      "Grain Chocolate                               520\n",
      "Crispy Rice Mango Peach                       520\n",
      "Crisp Mango Peach                             520\n",
      "Crunchy Bran Mango Peach                      520\n",
      "Lucjy Charms Chocolate                        520\n",
      "Muesli Chocolate                              520\n",
      "Corn Chocolate Choc Chip                      520\n",
      "Puffs Mango Peach                             520\n",
      "Stars Mango Peach                             520\n",
      "Sugar Chocolate Choc Chip                     520\n",
      "Cups Mango Peach                              520\n",
      "Fruit & Bran Mango Peach                      518\n",
      "Coco Poops Mango Peach                        518\n",
      "Nut Cheerios Chocolate Choc Chip              517\n",
      "Cornflakes Mango Peach                        516\n",
      "MultiGrain Chocolate Choc Chip                513\n",
      "Crunch Berries Mango Peach                    513\n",
      "Muesli Mango Peach                            507\n",
      "Squares Mango Peach                           506\n",
      "Graham Chocolate Choc Chip                    442\n",
      "Toast Chocolate                               364\n",
      "Frosted Mango Peach                           364\n",
      "Squares Chocolate                             364\n",
      "Peanut Butter Mango Peach                     364\n",
      "Peanut Butter Chocolate Choc Chip             337\n",
      "Chocos Chocolate Choc Chip                    218\n",
      "Sugar Mango Peach                             154\n",
      "Stars Chocolate                               154\n",
      "Crunchy Nut Cornflakes Chocolate Choc Chip    154\n",
      "Crunchy Bran Chocolate Choc Chip              154\n",
      "Lucjy Charms Mango Peach                      154\n",
      "Graham Mango Peach                            154\n",
      "Crunch Life Chocolate                         154\n",
      "Cornflakes Chocolate Choc Chip                154\n",
      "Coco Poops Chocolate Choc Chip                132\n",
      "Cookies Chocolate Choc Chip                    93\n",
      "Crispy Rice Chocolate Choc Chip                88\n",
      "Crunch Berries Chocolate Choc Chip             88\n",
      "Fruit & Nut Chocolate Choc Chip                81\n",
      "Fruit & Bran Chocolate Choc Chip               80\n",
      "Golden Goals Chocolate Choc Chip               79\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Quiero saber cuantos productos tienen ventas todos los días pues un requerimiento es tener ventas diarias \n",
    "# por producto. \n",
    "# Primero obtengo el numero total de días \n",
    "primero,ultimo = data_limpia['Date'].min(), data_limpia['Date'].max()\n",
    "dias = ultimo-primero\n",
    "\n",
    "# Ahora quiero saber cuantos días de venta tiene cada producto\n",
    "dias_producto = data_limpia.groupby('Descripcion').agg({'Date':['min','max']}).apply(lambda x: x[1]- x[0],axis = 1).apply(lambda x: x.days)\n",
    "\n",
    "# y quiero saber cuantos tienen 520 días\n",
    "# print(str((días_producto == 520).sum())+ ' productos tienen ventas todos los días')\n",
    "# print(dias_producto.sort_values(ascending=False)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ea7ccc",
   "metadata": {},
   "source": [
    "## Resultados y conclusiones.\n",
    "\n",
    "A primera vista los archivos tienen algunas inconsistencias en los formatos, eso en general hace que primero se tenga que hacer un poco de limpieza y algunos puntos son importantes preguntarlas al cliente para estar seguro de que los datos estén siendo interpretados de manera correcta.\n",
    "\n",
    "Algunos problemas de formato son:\n",
    "- Diferentes formatos para las fechas.\n",
    "- Símbolo de pesos en la columna 'Price'.\n",
    "- \"SO Diaria Piezas\" junto a la fecha.\n",
    "\n",
    "En cuanto a problemas y dudas con los datos surgen las siguientes dudas:\n",
    "- 580,000 de filas del archivo de ventas son filas con 0 en piezas y 0 en precio, eso es posiblemente un problema.\n",
    "- 110 filas de ventas son filas con precio 0 y piezas mayor a 0, tal vez sea algun tipo de promociones pero posiblemente un error.\n",
    "- La mitad de las filas tienen un valor con decimales en la columna de \"Pieces\", no necesariamente un error.\n",
    "\n",
    "### Las principales preguntas.\n",
    "\n",
    "Tratamos cada uno de los tres puntos requeridos por separado:\n",
    "1. Estos datos deben tener ventas para todos los productos del catálogo de productos.\n",
    "_Como lo vimos el archivo de venta solo contiene datos de 47 productos diferentes._\n",
    "2. Estos datos deben cubrir las ventas en todo el país de dos grupos de supermercados.\n",
    "_Tenemos que el proveedor 2 tiene tiendas en 32 estados y el proveedor 1 las tiene en 26. En cuanto a las ventas \n",
    "el proveedor 2 tiene ventas en cada uno de los estados y el proveedor 1 tiene ventas en 25 de 26 estados siendo la excepción 'Alfthrilmad'.\n",
    "3. Estos datos deben tener ventas diarias por producto.\n",
    "_De los 47 productos en el archivo de ventas 17 de ellos tienen registradas ventas en los 520 días, el numero numero de días que un producto tuvo ventas es 79._\n",
    "\n",
    "### Conclusión.\n",
    "\n",
    " - ¿Tenemos lo que pedimos? \n",
    "_No, hay una gran cantidad de productos en el catalogo que no tienen ventas, también hay algunas ventas que no tienen asignada una tienda. También es necesario el preguntar por la columna Pieces._\n",
    " - ¿Nos falta algo?\n",
    "_Si, faltan datos de ventas en algunas estados del proveedor 1 y por supuesto datos de venta de 2401 de un total de 2448_.\n",
    "\n",
    "Creo que en el tema del formato lo más fácil es explicarle que un formato más estandarizado evita muchas errores que pueden más tardado un análisis, aunque el formato no es tan complicado de corregir.\n",
    "\n",
    "Con respecto a el contenido en si de los datos, creo que preguntarle por la columna pieces y por las columnas con son 0 es muy util por que evitamos algunos errores que pueden afectar los resultados si no estamos seguros de como interpretarlos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
